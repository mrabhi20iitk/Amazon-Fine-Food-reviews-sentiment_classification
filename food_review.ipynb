{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId ProfileName  HelpfulnessNumerator   \n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW  delmartian                     1  \\\n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK      dll pa                     0   \n",
       "\n",
       "   HelpfulnessDenominator  Score        Time                Summary   \n",
       "0                       1      5  1303862400  Good Quality Dog Food  \\\n",
       "1                       0      1  1346976000      Not as Advertised   \n",
       "\n",
       "                                                Text  \n",
       "0  I have bought several of the Vitality canned d...  \n",
       "1  Product arrived labeled as Jumbo Salted Peanut...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Data/Reviews.csv')\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568454, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing\n",
    "EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                         0\n",
       "ProductId                  0\n",
       "UserId                     0\n",
       "ProfileName               26\n",
       "HelpfulnessNumerator       0\n",
       "HelpfulnessDenominator     0\n",
       "Score                      0\n",
       "Time                       0\n",
       "Summary                   27\n",
       "Text                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Cleaning\n",
    "# 1 . Handling null values\n",
    "#gives count of null values against each column\n",
    "data.isna().sum() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256059"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['UserId'].nunique(dropna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed_rows= 53\n"
     ]
    }
   ],
   "source": [
    "total_rows = data.shape[0]\n",
    "data.dropna(how = 'any', inplace=True)\n",
    "new_row_count = data.shape[0]\n",
    "print('removed_rows=',total_rows-new_row_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting data\n",
    "sorted_data = data.sort_values('ProductId',axis = 0 , ascending = True ,na_position = 'last' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.removing redundant data \n",
    "#removing duplicates\n",
    "sorted_data = sorted_data.drop_duplicates(subset = ['UserId'],keep='first')\n",
    "non_redundant = sorted_data.drop_duplicates(subset = ['UserId','Time','ProfileName','Text'],keep='first')\n",
    "# removing data where helpfulness numerator is smaller than helpfulness denominator\n",
    "non_redundant_data = non_redundant[non_redundant[\"HelpfulnessNumerator\"]<=non_redundant[\"HelpfulnessDenominator\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows_removed= 312359\n"
     ]
    }
   ],
   "source": [
    "b = non_redundant_data.shape[0]\n",
    "print('rows_removed=',new_row_count-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256042"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_redundant_data.shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_neg(x):\n",
    "    if x >3: \n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "filtered_data = non_redundant_data['Score'].map(pos_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_redundant_data['Score'] = filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256042"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = non_redundant_data\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Score\n",
       "1    199390\n",
       "0     56652\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(df['Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                        False\n",
       "ProductId                 False\n",
       "UserId                    False\n",
       "ProfileName               False\n",
       "HelpfulnessNumerator      False\n",
       "HelpfulnessDenominator    False\n",
       "Score                     False\n",
       "Time                      False\n",
       "Summary                   False\n",
       "Text                      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256042, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_preprocessing(i):\n",
    "# i = re.sub(r\"http\\S+\",\"\",i)        --removes HTTP content\n",
    "# i = re.sub(r\"[^A-Za-z0-9]+\",\" \",i)   --removes special characters and punctuations\n",
    "# i = re.sub('\\S*\\d\\S*',\"\",i)         --removes alpha-numeric words\n",
    "# i = BeautifulSoup(i).get_text()     --- to remove html content\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing decontraction e.g. can't = can not\n",
    "def decontraction(phrase):\n",
    "    phrase = re.sub(r\"won't\",\"will not\",phrase)\n",
    "    phrase = re.sub(r\"can't\",\"can not\",phrase)\n",
    "    phrase = re.sub(r\"doesn't\",\"does not\",phrase)\n",
    "    phrase = re.sub(r\"\\'t\",\"not\",phrase)\n",
    "    phrase = re.sub(r\"\\'d\",\"would\",phrase)\n",
    "    phrase = re.sub(r\"\\'s\",\" is\",phrase)\n",
    "    phrase = re.sub(r\"\\'ve\",\" have\",phrase)\n",
    "    phrase = re.sub(r\"\\'m\",\" am\",phrase)\n",
    "    phrase = re.sub(r\"\\'re\",\" are\",phrase)\n",
    "    return phrase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#converting to lower case\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([i\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43msentence\u001b[49m\u001b[38;5;241m.\u001b[39msplit()])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sentence' is not defined"
     ]
    }
   ],
   "source": [
    "#converting to lower case\n",
    "sentence = ' '.join([i.lower() for i in sentence.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "# sentence = \" \".join([i for i in sentence.split() if i not in nltk.stopwords('english')])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming words\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "# sentence = \" \".join([ps.stem(i) for i in sentence.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#progress bar\n",
    "from tqdm import tqdm\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for i in tqdm(df['Text'].values) :\n",
    "    i = re.sub(r'http\\S+','',str(i))                #removes HTTP content\n",
    "    i = decontraction(i)\n",
    "    i = re.sub(r\"[^A-Za-z0-9]+\",\" \",str(i))    #removes special characters and punctuations\n",
    "    i = re.sub('\\S*\\d\\S*',\"\",i)         #removes alpha-numeric words\n",
    "    i = BeautifulSoup(i).get_text()\n",
    "    i = ' '.join([j.lower() for j in i.split()])\n",
    "    i = \" \".join([j for j in i.split() if j not in stopwords.words('english')])\n",
    "    i = \" \".join([ps.stem(j) for j in i.split()])\n",
    "    corpus.append(i)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featurization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Featurization, also known as feature engineering, is the process of selecting, extracting, and transforming raw data into features that can be used as input to a machine learning model. The goal of featurization is to create a representation of the data that captures the most important information and relationships between the features and the target variable.\n",
    "Featurization in NLP :\n",
    "some of the methods are:\n",
    "1. BOW\n",
    "2. TF-IDF\n",
    "3. word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
